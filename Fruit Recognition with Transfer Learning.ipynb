{"cells":[{"metadata":{},"cell_type":"markdown","source":"**FRUIT RECOGNITION WITH TRANSFER LEARNING**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils import np_utils\nimport tensorflow as tf\nfrom sklearn.datasets import load_files\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\n\n# Input data files are available in the \"../input/\" directory.\n\nimport os\nfrom os import listdir, makedirs\nfrom os.path import join, exists, expanduser\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1. TRANSFER LEARNING**"},{"metadata":{"trusted":true},"cell_type":"code","source":"se","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dimensions of our images.\n\nimg_width, img_height = 224, 224 # we set the img_width and img_height according to the pretrained models we are\n# going to use. The input size for ResNet-50 is 224 by 224 by 3.\n\ntrain_data_dir = '../input/fruits/fruits-360_dataset/fruits-360/Training/'\nvalidation_data_dir = '../input/fruits/fruits-360_dataset/fruits-360/Test/'\nnb_train_samples = 61488\nnb_testing_samples = 20622\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data = pd.DataFrame(train_generator.classes, columns=['classes'])\ntesting_data = pd.DataFrame(validation_generator.classes, columns=['classes'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_stack_bar_data(col, df):\n    aggregated = df[col].value_counts().sort_index()\n    x_values = aggregated.index.tolist()\n    y_values = aggregated.values.tolist()\n    return x_values, y_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1, y1 = create_stack_bar_data('classes', training_data)\nx1 = list(train_generator.class_indices.keys())\n\ntrace1 = go.Bar(x=x1, y=y1, opacity=0.75, name=\"Class Count\")\nlayout = dict(height=400, width=1200, title='Class Distribution in Training Data', legend=dict(orientation=\"h\"), \n                yaxis = dict(title = 'Class Count'))\nfig = go.Figure(data=[trace1], layout=layout);\niplot(fig);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1, y1 = create_stack_bar_data('classes', testing_data)\nx1 = list(validation_generator.class_indices.keys())\n\ntrace1 = go.Bar(x=x1, y=y1, opacity=0.75, name=\"Class Count\")\nlayout = dict(height=400, width=1100, title='Class Distribution in Validation Data', legend=dict(orientation=\"h\"), \n                yaxis = dict(title = 'Class Count'))\nfig = go.Figure(data=[trace1], layout=layout);\niplot(fig);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building pretrained model\n#import inception with pre-trained weights. do not include fullyconnected layers\n\ninception_base = applications.ResNet50(weights='imagenet', include_top=False)\n\n# add a global spatial average pooling layer\nx = inception_base.output\nx = GlobalAveragePooling2D()(x)\n# add a fully-connected layer\nx = Dense(512, activation='relu')(x)\n# and a fully connected output/classification layer\npredictions = Dense(120, activation='softmax')(x)\n# create the full network so we can train on it\ninception_transfer = Model(inputs=inception_base.input, outputs=predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building vanilla model\n#import inception with pre-trained weights. do not include fully #connected layers\n\ninception_base_vanilla = applications.ResNet50(weights=None, include_top=False)\n\n# add a global spatial average pooling layer\nx = inception_base_vanilla.output\nx = GlobalAveragePooling2D()(x)\n# add a fully-connected layer\nx = Dense(512, activation='relu')(x)\n# and a fully connected output/classification layer\npredictions = Dense(120, activation='softmax')(x)\n# create the full network so we can train on it\ninception_transfer_vanilla = Model(inputs=inception_base_vanilla.input, outputs=predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Compiling the models\n\ninception_transfer.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\ninception_transfer_vanilla.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\n\ndef fxn():\n    warnings.warn(\"deprecated\", DeprecationWarning)\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    fxn()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training and validating the pretrained model\n\nimport tensorflow as tf\nwith tf.device(\"/device:GPU:0\"):\n    history_pretrained = inception_transfer.fit_generator(\n    train_generator,\n    epochs=5, shuffle = True, verbose = 1, validation_data = validation_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.device(\"/device:GPU:0\"):\n    history_vanilla = inception_transfer_vanilla.fit_generator(\n    train_generator,\n    epochs=5, shuffle = True, verbose = 1, validation_data = validation_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n# summarize history for accuracy\nplt.plot(history_pretrained.history['val_acc'])\nplt.plot(history_vanilla.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['Pretrained', 'Vanilla'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history_pretrained.history['val_loss'])\nplt.plot(history_vanilla.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['Pretrained', 'Vanilla'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}