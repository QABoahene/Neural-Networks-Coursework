{"cells":[{"metadata":{},"cell_type":"markdown","source":"**FRUIT RECOGNITION WITH CNN**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils import np_utils\nimport tensorflow as tf\nfrom sklearn.datasets import load_files\n\n# Input data files are available in the \"../input/\" directory.\n\nimport os\nfrom os import listdir, makedirs\nfrom os.path import join, exists, expanduser\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading the file names and their respective target labels into an array\n\ntrain_dir = '../input/fruits/fruits-360_dataset/fruits-360/Training/'\ntest_dir = '../input/fruits/fruits-360_dataset/fruits-360/Test/'\n\ndef load_dataset (path):\n    data = load_files (path)\n    files = np.array (data ['filenames'])\n    targets = np.array (data ['target'])\n    target_labels = np.array (data ['target_names'])\n    return files, targets, target_labels\n\nx_train, y_train, target_labels = load_dataset (train_dir)\nx_test, y_test,_ = load_dataset (test_dir)\nprint (\"LOADING COMPLETE\")\n\nprint (\"TRAINING SET SIZE: \", x_train.shape[0])\nprint (\"TESTING SET SIZE: \", x_test.shape[0])\nnum_of_classes = len (np.unique (y_train))\nprint (\"NUMBER OF CLASSES:\", num_of_classes) #Confirming the number of classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 224, 224 # we set the img_width and img_height according to the pretrained models we are\n# going to use. The input size for ResNet-50 is 224 by 224 by 3.\n\ntrain_data_dir = '../input/fruits/fruits-360_dataset/fruits-360/Training/'\nvalidation_data_dir = '../input/fruits/fruits-360_dataset/fruits-360/Test/'\nnb_train_samples = 61488\nnb_testing_samples = 20622\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (y_train [0:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import np_utils\ny_train = np_utils.to_categorical (y_train, num_of_classes)\ny_test = np_utils.to_categorical (y_test, num_of_classes)\ny_train [0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dividing the validation set into test and validation set\n\nx_test,x_valid = x_test[7000:],x_test[:7000]\ny_test,y_vaild = y_test[7000:],y_test[:7000]\nprint('VALIDATION X : ',x_valid.shape)\nprint('VALIDATION Y :',y_vaild.shape)\nprint('TEST X : ',x_test.shape)\nprint('TEST Y : ',y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train[0] #training and converting file names of images into pixel matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading file names in the set x and converting them into arrays\n\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\n\ndef convert_image_to_array(files):\n    images_as_array=[]\n    for file in files:\n        # Convert to Numpy Array\n        images_as_array.append(img_to_array(load_img(file)))\n    return images_as_array\n\nx_train = np.array(convert_image_to_array(x_train))\nprint('Training set shape : ',x_train.shape)\n\nx_valid = np.array(convert_image_to_array(x_valid))\nprint('Validation set shape : ',x_valid.shape)\n\nx_test = np.array(convert_image_to_array(x_test))\nprint('Test set shape : ',x_test.shape)\n\nprint('1st training image shape ',x_train[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('1st training image as array',x_train[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rescaling so all the pixel values lie within 0 - 1\n\nx_train = x_train.astype('float32')/255\nx_valid = x_valid.astype('float32')/255\nx_test = x_test.astype('float32')/255\nx_train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig = plt.figure(figsize =(30,5))\nfor i in range(10):\n    ax = fig.add_subplot(2,5,i+1,xticks=[],yticks=[])\n    ax.imshow(np.squeeze(x_train[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using three convolutional layers followed by maxpooling layers\n#Lastly, we add dropout, flatten ans some fully connected layers (Dense)\n\nmodel = Sequential()\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3), strides=(2,2),input_shape=(224,224,3),padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(200))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(120,activation = 'softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\nprint('Compiled!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_pretrained = model.fit_generator(train_generator,\n                                         epochs=5, shuffle = True, verbose = 1, validation_data = validation_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loadung weights that yielded the best validation accuracy\n\nmodel.load_weights('cnn_from_scratch_fruits.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluation\n\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('\\n', 'Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test prediction visualisation\n\ny_pred = model.predict(x_test)\n\n# plot a random sample of test images, their predicted labels, and ground truth\nfig = plt.figure(figsize=(16, 9))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx = np.argmax(y_pred[idx])\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n                 color=(\"green\" if pred_idx == true_idx else \"red\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1)   \nplt.subplot(211)  \nplt.plot(history.history['acc'])  \nplt.plot(history.history['val_acc'])  \nplt.title('model accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')   \n   \nplt.subplot(212)  \nplt.plot(history.history['loss'])  \nplt.plot(history.history['val_loss'])  \nplt.title('model loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')  \nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}